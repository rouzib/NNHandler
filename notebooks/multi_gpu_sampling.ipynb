{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-17T16:04:52.881372Z",
     "start_time": "2025-06-17T16:04:51.534807Z"
    }
   },
   "source": "import torch",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:04:53.152777Z",
     "start_time": "2025-06-17T16:04:53.074948Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.device_count()",
   "id": "38fce6d6445e8107",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:04:53.172407Z",
     "start_time": "2025-06-17T16:04:53.168682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sample(device):\n",
    "    model = lambda x: x**2 + 3\n",
    "    return model(torch.randint(0, 1000, (10,), device=device))"
   ],
   "id": "8cc7ab96ff9e366a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:04:53.686068Z",
     "start_time": "2025-06-17T16:04:53.226385Z"
    }
   },
   "cell_type": "code",
   "source": "sample(torch.device('cuda:0'))",
   "id": "1e46cdddf8b56498",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([335244, 302503,  19884, 384403, 810003, 839059, 693892, 233292, 952579,\n",
       "        574567], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:04:54.197757Z",
     "start_time": "2025-06-17T16:04:53.702257Z"
    }
   },
   "cell_type": "code",
   "source": "from src.nn_handler import parallelize_on_gpus",
   "id": "9f3e674a18f06844",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:04:54.214799Z",
     "start_time": "2025-06-17T16:04:54.211130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@parallelize_on_gpus()\n",
    "def sample_gpu(device):\n",
    "    \"\"\"\n",
    "    This function will be executed on a specific GPU.\n",
    "    The `device` argument (e.g., 'cuda:0', 'cuda:1') is provided by the decorator.\n",
    "    \"\"\"\n",
    "    # Create the model on the correct device (if it were a real nn.Module)\n",
    "    model = lambda x: x**2 + 3\n",
    "\n",
    "    # Create the input tensor directly on the target device\n",
    "    input_tensor = torch.randint(0, 1000, (10,), device=device)\n",
    "\n",
    "    print(f\"Running on device: {torch.get_device(input_tensor)}\")\n",
    "\n",
    "    return model(input_tensor).cpu().numpy()"
   ],
   "id": "113cc03f50bc4a69",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:04:57.225815Z",
     "start_time": "2025-06-17T16:04:54.258909Z"
    }
   },
   "cell_type": "code",
   "source": "sample_gpu()",
   "id": "cd20a0a3015c1b2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: 0\n",
      "Running on device: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([990028, 868627,   8467,  84684, 549084,  21612, 429028, 480252,\n",
       "         31332, 234259]),\n",
       " array([255028,  37252, 192724,  16132,  84103,    444, 683932, 174727,\n",
       "        376999, 279844])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:05:00.156388Z",
     "start_time": "2025-06-17T16:04:57.255781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Similarly, if you use only .cuda() and .cpu() placements, it is handled automatically and no device argument is needed.\n",
    "@parallelize_on_gpus(pass_device=False)\n",
    "def sample_gpu():\n",
    "    \"\"\"\n",
    "    This function will be executed on a specific GPU.\n",
    "    The `device` argument (e.g., 'cuda:0', 'cuda:1') is provided by the decorator.\n",
    "    \"\"\"\n",
    "    # Create the model on the correct device (if it were a real nn.Module)\n",
    "    model = lambda x: x**2 + 3\n",
    "\n",
    "    # Create the input tensor and pass it to the target device\n",
    "    input_tensor = torch.randint(0, 1000, (2000,)).cuda()\n",
    "\n",
    "    print(f\"Running on device: {torch.get_device(input_tensor)}\")\n",
    "\n",
    "    return model(input_tensor).cpu().numpy()\n",
    "\n",
    "sample_gpu()"
   ],
   "id": "465706551a077ad2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: 0\n",
      "Running on device: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([525628,   5932, 237172, ..., 220903, 153667, 418612]),\n",
       " array([978124, 698899,   6564, ...,  36867, 715719, 760387])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:05:09.380941Z",
     "start_time": "2025-06-17T16:05:00.185421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@parallelize_on_gpus()\n",
    "def heavy_gpu_work(device: torch.device, *, n: int = 4096, steps: int = 20) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    A computationally intensive task: repeatedly multiply two large matrices\n",
    "    of shape (n, n) on a given device.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    device : torch.device\n",
    "        Target CUDA device.\n",
    "    n : int\n",
    "        Size of the square matrices. 4096 → ~128 MB per matrix in FP32.\n",
    "    steps : int\n",
    "        Number of multiply–assign iterations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Final matrix produced by the loop (still on `device`).\n",
    "    \"\"\"\n",
    "    # Two random matrices on the selected GPU\n",
    "    a = torch.randn(n, n, device=device, dtype=torch.float32)\n",
    "    b = torch.randn(n, n, device=device, dtype=torch.float32)\n",
    "\n",
    "    # Repeated multiplications to ensure heavy load\n",
    "    for _ in range(steps):\n",
    "        c = a @ b\n",
    "        # Re-use the result in the next iteration to keep the memory footprint stable\n",
    "        a, b = b, c\n",
    "\n",
    "    return c.cpu().numpy()\n",
    "\n",
    "\n",
    "heavy_gpu_work(n=64**2, steps=1000)"
   ],
   "id": "3f290bc423fee7ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]], dtype=float32),\n",
       " array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:05:21.192879Z",
     "start_time": "2025-06-17T16:05:09.401028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def heavy_gpu_work(device: torch.device, *, n: int = 4096, steps: int = 20) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    A computationally intensive task: repeatedly multiply two large matrices\n",
    "    of shape (n, n) on a given device.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    device : torch.device\n",
    "        Target CUDA device.\n",
    "    n : int\n",
    "        Size of the square matrices. 4096 → ~128 MB per matrix in FP32.\n",
    "    steps : int\n",
    "        Number of multiply–assign iterations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Final matrix produced by the loop (still on `device`).\n",
    "    \"\"\"\n",
    "    # Two random matrices on the selected GPU\n",
    "    a = torch.randn(n, n, device=device, dtype=torch.float32)\n",
    "    b = torch.randn(n, n, device=device, dtype=torch.float32)\n",
    "\n",
    "    # Repeated multiplications to ensure heavy load\n",
    "    for _ in range(steps):\n",
    "        c = a @ b\n",
    "        # Re-use the result in the next iteration to keep the memory footprint stable\n",
    "        a, b = b, c\n",
    "\n",
    "    return c.cpu().numpy()\n",
    "\n",
    "\n",
    "heavy_gpu_work(torch.device(\"cuda:1\"), n=64**2, steps=1000 * 2)"
   ],
   "id": "8f6bd6c86086a3ee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:05:21.226523Z",
     "start_time": "2025-06-17T16:05:21.223796Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2d1fed523d92778f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
